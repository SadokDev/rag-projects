{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8159e3a4",
   "metadata": {},
   "source": [
    "# Building a News Article Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install newspaper3k lxml_html_clean langchain langchain-cohere python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be990372",
   "metadata": {},
   "source": [
    "The \"COHERE_API_KEY\" is stored in .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import cohere\n",
    "import json\n",
    "\n",
    "co = cohere.Client(os.getenv(\"COHERE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e967fd8",
   "metadata": {},
   "source": [
    "Use the newspapaer library to extract the title and text of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfa2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "}\n",
    "article_url =\"\"\"https://www.artificialintelligence-news.com/news/meta-claims-new-ai-supercomputer-will-set-records/\"\"\"\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "try:\n",
    "    response = session.get(article_url, headers=headers, timeout=10)\n",
    "    if(response.status_code == 200):\n",
    "        article = Article(article_url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "\n",
    "        print(f\"Title : {article.title}\")\n",
    "        print(f\"Text : {article.text}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch article at {article_url}\")\n",
    "except Exception as e:\n",
    "        print(\"Error occured while fetching article at {article_url} : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07976b4d",
   "metadata": {},
   "source": [
    "The HumanMessage is a structured data format that captures user messages within chat-based interactions. In the following code, the ChatCohere class is employed for interaction with the AI model and the HumanMessage schema permits a standarized format for user messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    HumanMessage\n",
    ")\n",
    "article_title = article.title\n",
    "article_text = article.text\n",
    "\n",
    "template = \"\"\"\n",
    "You are a very good assistant that summarizes online articles.\n",
    "Here's the artcile you want to summarize.\n",
    "===================\n",
    "Title: {article_title}\n",
    "{article_text}\n",
    "\n",
    "===================\n",
    "Write a summary of the previous article\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(article_title = article.title, article_text = article.text)\n",
    "\n",
    "messages = [HumanMessage(content=prompt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e724de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cohere\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "co = cohere.Client(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "# Define the Cohere LLM\n",
    "llm = ChatCohere(\n",
    "    cohere_api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "    model=\"command-a-03-2025\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9969947",
   "metadata": {},
   "source": [
    "The model processes the prompt and returns the summary :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc7adb",
   "metadata": {},
   "source": [
    "Modify the propmt to ask for a bulleted list format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bullet lists.\n",
    "Here's the article you want to summarize.\n",
    "\n",
    "========================\n",
    "Title : {article_title}\n",
    "\n",
    "{article_text}\n",
    "========================\n",
    "\n",
    "Now, provide a summarized version of the article in a bulleted list format.\n",
    "\"\"\"\n",
    "\n",
    "# format prompt\n",
    "prompt = template.format(article_title= article.title, article_text=article.text)\n",
    "#generate summary\n",
    "message = [HumanMessage(content=prompt)]\n",
    "print(llm.invoke(message).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c463a",
   "metadata": {},
   "source": [
    "### Improving the summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd08dae",
   "metadata": {},
   "source": [
    "I will use the PydanticOutputParser class. This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON outputs that conform to that schema. The goal here is to convert the language model's string output into a strcutured data format. I will use a custom class derived from the BaseModel class of the Pydantic package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import field_validator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# create output parser class\n",
    "class ArticleSummary(BaseModel):\n",
    "    title: str = Field(description=\"Title of the article\")\n",
    "    summary: List[str] = Field(description=\"\"\"Bulleted list summary of the article\"\"\")\n",
    "    #validating whether the generated summary has at least three lines\n",
    "    @field_validator('summary')\n",
    "    def has_three_or_more_lines(cls, list_of_lines):\n",
    "        if(len(list_of_lines) < 3):\n",
    "            raise ValueError(\"\"\"Generated summary has less than three bullet points!\"\"\")\n",
    "        return list_of_lines\n",
    "    \n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ArticleSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt template integrates the custom parser to format the prompts\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a very good assistant that summarizes online articles.\n",
    "Here's the article you want to summarize.\n",
    "===================\n",
    "Title: {article_title}\n",
    "{article_text}\n",
    "\n",
    "===================\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"article_title\", \"article_text\"],\n",
    "    partial_variables={\"format_instructions\" : parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bcfee",
   "metadata": {},
   "source": [
    "Transforming the string output from the model into a specified format :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d705ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "model = ChatCohere(\n",
    "    cohere_api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "    model=\"command-a-03-2025\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt_template)\n",
    "#Use the model to generate a summary\n",
    "output = chain.run({\"article_title\" : article_title, \"article_text\" : article_text})\n",
    "\n",
    "#Parse the output into the Pydantic model\n",
    "parsed_output = parser.parse(output)\n",
    "print(parsed_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
